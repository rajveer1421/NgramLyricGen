{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c221b5-2313-4a04-b432-6ee6e727d73c",
   "metadata": {},
   "source": [
    "# **Building and Training a Feedforward Neural Network for Language Modeling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191cf47-a329-435f-b9fc-9d97ac0b61e2",
   "metadata": {},
   "source": [
    "### Importing The Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c00436-5793-4469-9908-5e33a4fbd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import string\n",
    "import time\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d68303-c712-4d06-87d2-764965a843c6",
   "metadata": {},
   "source": [
    "### Defining Preprocessing Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61a3255-eeef-4fdf-90df-c5f128daace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    \"\"\"\n",
    "    Preprocesses a given string by performing the following steps:\n",
    "    \n",
    "    1. Removes all non-word characters (excluding letters and numbers).\n",
    "    2. Removes all whitespace characters.\n",
    "    3. Removes all numeric digits.\n",
    "\n",
    "    Parameters:\n",
    "    s (str): The input string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    str: The processed string with only alphabetic characters, no spaces, and no digits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all non-word characters (everything except letters and numbers)\n",
    "    # \\w matches any word character (letters, numbers, and underscores)\n",
    "    # \\s matches any whitespace characters\n",
    "    # ^ inside [] negates the selection, so [^\\w\\s] matches anything that's NOT a word character or whitespace.\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "\n",
    "    # Remove all whitespace characters (spaces, tabs, newlines)\n",
    "    # \\s+ matches one or more whitespace characters.\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "\n",
    "    # Remove all digits (0-9)\n",
    "    # \\d matches any digit character.\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1b9aec-3e0f-4d97-88c1-3ca7e7771258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(word):\n",
    "    tokens=word_tokenize(word)\n",
    "    tokens=[preprocess_string(token) for token in tokens]\n",
    "    tokens=[token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0f69df-3d3e-4a4e-99d6-2f0a5320d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_indices(tokens):\n",
    "    vocab = build_vocab_from_iterator([tokens],specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608573f-d89d-4404-bc12-66211d778c95",
   "metadata": {},
   "source": [
    "### Giving Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ec1154-fe24-4126-a0d9-654632aab24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "song= \"\"\"We are no strangers to love\n",
    "You know the rules and so do I\n",
    "A full commitments what Im thinking of\n",
    "You wouldnt get this from any other guy\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "And if you ask me how Im feeling\n",
    "Dont tell me youre too blind to see\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c90e75-0b9a-49c9-a449-04a7568307a2",
   "metadata": {},
   "source": [
    "### Preprocessing The Input song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe3ad97-11ad-45e2-9bed-deeaabd6beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=process(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b3abeb-6492-4e2b-ac02-c98d74d09515",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=convert_to_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f1c8d5-5044-44fc-92b9-8d460997d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "60\n",
      "72\n",
      "76\n",
      "26\n",
      "71\n",
      "3\n",
      "21\n",
      "32\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "for token in tokens[0:10]:\n",
    "    print(vocab[token]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095b681a-66a1-4464-a0f9-fc087aeac29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(vocab):\n",
    "    embedding_dim=20\n",
    "    vocab_size=len(vocab)\n",
    "    return nn.Embedding(vocab_size,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d5da052-dfbb-4f9b-a63d-1a1b08e1339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 602, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\rajve\\AppData\\Local\\Temp\\ipykernel_17144\\400737762.py\", line 1, in <module>\n",
      "    embeddings=get_embedding(vocab)\n",
      "  File \"C:\\Users\\rajve\\AppData\\Local\\Temp\\ipykernel_17144\\2969537762.py\", line 4, in get_embedding\n",
      "    return nn.Embedding(vocab_size,embedding_dim)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 145, in __init__\n",
      "    self.reset_parameters()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 154, in reset_parameters\n",
      "    init.normal_(self.weight)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\init.py\", line 175, in normal_\n",
      "    return _no_grad_normal_(tensor, mean, std, generator)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\init.py\", line 20, in _no_grad_normal_\n",
      "    return tensor.normal_(mean, std, generator=generator)\n"
     ]
    }
   ],
   "source": [
    "embeddings=get_embedding(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f624d7-4ff9-4da1-aa97-967562172624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word <unk>\n",
      "index 0\n",
      "embedding tensor([ 1.8901,  0.3956, -0.3977, -0.3144,  0.0081,  0.0214, -1.0338, -2.5969,\n",
      "        -0.1704,  0.2626, -1.0628, -1.3763,  0.9188, -1.6850,  0.7507,  0.2583,\n",
      "         1.3888,  0.6482, -0.9211,  0.5353], grad_fn=<EmbeddingBackward0>)\n",
      "embedding shape torch.Size([20])\n",
      "word na\n",
      "index 1\n",
      "embedding tensor([ 0.7926, -2.0075, -1.0527, -0.2150,  0.0782,  0.1578,  0.2381, -0.3948,\n",
      "         1.4990,  0.5304, -0.6798,  0.1766,  1.8218, -1.3973,  0.8606, -0.0515,\n",
      "         1.1187, -0.9006, -0.5457,  0.2750], grad_fn=<EmbeddingBackward0>)\n",
      "embedding shape torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "index_to_token=vocab.get_itos()\n",
    "for n in range(2): \n",
    "    embedding=embeddings(torch.tensor(n))\n",
    "    print(\"word\",index_to_token[n])\n",
    "    print(\"index\",n)\n",
    "    print( \"embedding\", embedding)\n",
    "    print(\"embedding shape\", embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5701692-714e-465d-81f5-68b0f7cade9f",
   "metadata": {},
   "source": [
    "### Defining The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e427d22-992b-4975-83e3-d90ac74bdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dim=20):\n",
    "        super(NGramLanguageModel,self).__init__()\n",
    "        self.embed=nn.Embedding(vocab_size,embed_dim)\n",
    "        self.linear1=nn.Linear(Context_Size*embed_dim,128)\n",
    "        self.linear2=nn.Linear(128,64)\n",
    "        self.out=nn.Linear(64,vocab_size)\n",
    "    def forward(self, inp_indx):\n",
    "        \n",
    "        inp_embed = self.embed(torch.tensor(inp_indx))\n",
    "        \n",
    "        inp_embed=inp_embed.view(1,-1)\n",
    "        \n",
    "        outp = torch.relu(self.linear1(inp_embed))\n",
    "        outp = torch.relu(self.linear2(outp))\n",
    "        \n",
    "        return self.out(outp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "262537d4-29cf-47c3-b2ae-b92927e90607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_final_indx(out):\n",
    "    return torch.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51a423a8-5cd4-4d07-b8b7-31d59d9254bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_final_string(idx):\n",
    "    return index_to_token(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30434e-6571-44fd-9ba4-7773bcbdda40",
   "metadata": {},
   "source": [
    "### Structuring The Input before passing it to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a804670-2abe-4408-99bc-96dc439bb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "Context_Size=2\n",
    "input_structured=[\n",
    "                    (\n",
    "                      [vocab[tokens[i-j-1]] for j in range(Context_Size)],\n",
    "                       vocab[tokens[i]])\n",
    "                      for i in range(Context_Size,len(vocab))\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ef076a7-8505-4824-b750-6e8e72905c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([60, 22], 72)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_structured[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "104b327f-34cf-4e7b-a83f-d798b14fa9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader=DataLoader(input_structured,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "500ff5b7-5017-4f3d-82e7-14d38f691e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [tensor([60]), tensor([22])]\n",
      "Target: tensor([72])\n",
      "Context: [tensor([72]), tensor([60])]\n",
      "Target: tensor([76])\n",
      "Context: [tensor([76]), tensor([72])]\n",
      "Target: tensor([26])\n",
      "Context: [tensor([26]), tensor([76])]\n",
      "Target: tensor([71])\n",
      "Context: [tensor([71]), tensor([26])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([71])]\n",
      "Target: tensor([21])\n",
      "Context: [tensor([21]), tensor([3])]\n",
      "Target: tensor([32])\n",
      "Context: [tensor([32]), tensor([21])]\n",
      "Target: tensor([74])\n",
      "Context: [tensor([74]), tensor([32])]\n",
      "Target: tensor([5])\n",
      "Context: [tensor([5]), tensor([74])]\n",
      "Target: tensor([31])\n",
      "Context: [tensor([31]), tensor([5])]\n",
      "Target: tensor([64])\n",
      "Context: [tensor([64]), tensor([31])]\n",
      "Target: tensor([29])\n",
      "Context: [tensor([29]), tensor([64])]\n",
      "Target: tensor([9])\n",
      "Context: [tensor([9]), tensor([29])]\n",
      "Target: tensor([67])\n",
      "Context: [tensor([67]), tensor([9])]\n",
      "Target: tensor([63])\n",
      "Context: [tensor([63]), tensor([67])]\n",
      "Target: tensor([79])\n",
      "Context: [tensor([79]), tensor([63])]\n",
      "Target: tensor([24])\n",
      "Context: [tensor([24]), tensor([79])]\n",
      "Target: tensor([77])\n",
      "Context: [tensor([77]), tensor([24])]\n",
      "Target: tensor([73])\n",
      "Context: [tensor([73]), tensor([77])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([73])]\n",
      "Target: tensor([80])\n",
      "Context: [tensor([80]), tensor([3])]\n",
      "Target: tensor([68])\n",
      "Context: [tensor([68]), tensor([80])]\n",
      "Target: tensor([78])\n",
      "Context: [tensor([78]), tensor([68])]\n",
      "Target: tensor([66])\n",
      "Context: [tensor([66]), tensor([78])]\n",
      "Target: tensor([59])\n",
      "Context: [tensor([59]), tensor([66])]\n",
      "Target: tensor([30])\n",
      "Context: [tensor([30]), tensor([59])]\n",
      "Target: tensor([69])\n",
      "Context: [tensor([69]), tensor([30])]\n",
      "Target: tensor([29])\n",
      "Context: [tensor([29]), tensor([69])]\n",
      "Target: tensor([45])\n",
      "Context: [tensor([45]), tensor([29])]\n",
      "Target: tensor([54])\n",
      "Context: [tensor([54]), tensor([45])]\n",
      "Target: tensor([1])\n",
      "Context: [tensor([1]), tensor([54])]\n",
      "Target: tensor([6])\n",
      "Context: [tensor([6]), tensor([1])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([6])]\n",
      "Target: tensor([28])\n",
      "Context: [tensor([28]), tensor([3])]\n",
      "Target: tensor([24])\n",
      "Context: [tensor([24]), tensor([28])]\n",
      "Target: tensor([27])\n",
      "Context: [tensor([27]), tensor([24])]\n",
      "Target: tensor([42])\n",
      "Context: [tensor([42]), tensor([27])]\n",
      "Target: tensor([52])\n",
      "Context: [tensor([52]), tensor([42])]\n",
      "Target: tensor([7])\n",
      "Context: [tensor([7]), tensor([52])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([7])]\n",
      "Target: tensor([53])\n",
      "Context: [tensor([53]), tensor([3])]\n",
      "Target: tensor([4])\n",
      "Context: [tensor([4]), tensor([53])]\n",
      "Target: tensor([2])\n",
      "Context: [tensor([2]), tensor([4])]\n",
      "Target: tensor([1])\n",
      "Context: [tensor([1]), tensor([2])]\n",
      "Target: tensor([14])\n",
      "Context: [tensor([14]), tensor([1])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([14])]\n",
      "Target: tensor([20])\n",
      "Context: [tensor([20]), tensor([3])]\n",
      "Target: tensor([4])\n",
      "Context: [tensor([4]), tensor([20])]\n",
      "Target: tensor([2])\n",
      "Context: [tensor([2]), tensor([4])]\n",
      "Target: tensor([1])\n",
      "Context: [tensor([1]), tensor([2])]\n",
      "Target: tensor([17])\n",
      "Context: [tensor([17]), tensor([1])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([17])]\n",
      "Target: tensor([13])\n",
      "Context: [tensor([13]), tensor([3])]\n",
      "Target: tensor([4])\n",
      "Context: [tensor([4]), tensor([13])]\n",
      "Target: tensor([2])\n",
      "Context: [tensor([2]), tensor([4])]\n",
      "Target: tensor([1])\n",
      "Context: [tensor([1]), tensor([2])]\n",
      "Target: tensor([19])\n",
      "Context: [tensor([19]), tensor([1])]\n",
      "Target: tensor([10])\n",
      "Context: [tensor([10]), tensor([19])]\n",
      "Target: tensor([5])\n",
      "Context: [tensor([5]), tensor([10])]\n",
      "Target: tensor([12])\n",
      "Context: [tensor([12]), tensor([5])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([12])]\n",
      "Target: tensor([4])\n",
      "Context: [tensor([4]), tensor([3])]\n",
      "Target: tensor([2])\n",
      "Context: [tensor([2]), tensor([4])]\n",
      "Target: tensor([1])\n",
      "Context: [tensor([1]), tensor([2])]\n",
      "Target: tensor([7])\n",
      "Context: [tensor([7]), tensor([1])]\n",
      "Target: tensor([3])\n",
      "Context: [tensor([3]), tensor([7])]\n",
      "Target: tensor([11])\n",
      "Context: [tensor([11]), tensor([3])]\n",
      "Target: tensor([4])\n",
      "Context: [tensor([4]), tensor([11])]\n",
      "Target: tensor([2])\n",
      "Context: [tensor([2]), tensor([4])]\n",
      "Target: tensor([1])\n",
      "Context: [tensor([1]), tensor([2])]\n",
      "Target: tensor([8])\n",
      "Context: [tensor([8]), tensor([1])]\n",
      "Target: tensor([15])\n",
      "Context: [tensor([15]), tensor([8])]\n",
      "Target: tensor([4])\n",
      "Context: [tensor([4]), tensor([15])]\n",
      "Target: tensor([2])\n",
      "Context: [tensor([2]), tensor([4])]\n",
      "Target: tensor([1])\n",
      "Context: [tensor([1]), tensor([2])]\n",
      "Target: tensor([6])\n",
      "Context: [tensor([6]), tensor([1])]\n",
      "Target: tensor([9])\n",
      "Context: [tensor([9]), tensor([6])]\n",
      "Target: tensor([18])\n",
      "Context: [tensor([18]), tensor([9])]\n",
      "Target: tensor([5])\n"
     ]
    }
   ],
   "source": [
    "for context,target in dataloader:\n",
    "    print(\"Context:\",context)\n",
    "    print(\"Target:\",target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33b97bfa-059a-46bf-8443-a4b80914c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d57ac95-5e7f-4894-bebb-605aedc8cf89",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "178c868a-28eb-4554-a491-6ee6b7eb0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NGramLanguageModel(vocab_size=len(vocab),embed_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b5455b3-35bc-4839-9534-25621b20c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8b8f521-6874-42d1-b7a1-e103992c9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(dataloader,model,epoch=100,show=10):\n",
    "    model.train()\n",
    "    loss_history=[]\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        total_loss=0\n",
    "        for context,target in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predicted=model(context)\n",
    "            Loss=loss(predicted,target.reshape(-1))\n",
    "            total_loss+=Loss.item()\n",
    "            Loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_history.append(total_loss)\n",
    "        \n",
    "        if (epoch + 1) % show == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss {total_loss:.4f}\")\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3d60c7c-a240-4fed-9395-d8ae47100389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▉                                                                        | 11/100 [00:02<00:19,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss 187.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▏                                                                | 20/100 [00:04<00:25,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss 175.2827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▎                                                        | 30/100 [00:08<00:23,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss 162.9539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▏                                               | 41/100 [00:10<00:09,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Loss 150.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▌                                        | 50/100 [00:12<00:10,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Loss 137.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▌                                | 60/100 [00:14<00:11,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Loss 124.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▋                        | 70/100 [00:16<00:05,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Loss 110.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████▌               | 81/100 [00:19<00:03,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Loss 98.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████▋       | 91/100 [00:21<00:01,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Loss 86.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:22<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss 75.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_history=train(dataloader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e223c0d4-bacf-415e-8e6c-a24eb1947e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6fb14-9cca-4dbd-8fa3-45daa77419b8",
   "metadata": {},
   "source": [
    "### Calculating Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08393da6-e8ed-4de5-abe1-80e0c858b085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.7332419967990015e+32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c294fe-2c09-42ba-a61d-c48661567fa3",
   "metadata": {},
   "source": [
    "### Testing Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "acdfd359-1fff-4783-b465-498c6c7d62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_song_lines(model, vocab, seed_tokens, max_length=20, temperature=1.0):\n",
    "    model.eval()\n",
    "    stoi = vocab.get_stoi()\n",
    "    itos = vocab.get_itos()\n",
    "    \n",
    "    generated_indices = [stoi[token] for token in seed_tokens]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            input_window = torch.tensor([generated_indices[-Context_Size:]])\n",
    "            output = model(input_window)\n",
    "            probs = torch.softmax(output / temperature, dim=1).squeeze()\n",
    "            next_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "            generated_indices.append(next_idx)\n",
    "\n",
    "    return \" \".join([itos[idx] for idx in generated_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ad35fbc-af8d-4de8-9153-88ab864210b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love what of wan of na you i got you im let gon up na a around a and full around\n"
     ]
    }
   ],
   "source": [
    "seed = [\"i\", \"love\"] \n",
    "\n",
    "lyrics = generate_song_lines(model, vocab, seed, max_length=20)\n",
    "\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489e3d7-0cd3-4403-b9a7-77194f322a40",
   "metadata": {},
   "source": [
    "### Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "755b7c26-b792-4f5b-8feb-21fce1d5939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"complete_ngram_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbc361-4cf4-445c-b0fa-cd92e37967aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
